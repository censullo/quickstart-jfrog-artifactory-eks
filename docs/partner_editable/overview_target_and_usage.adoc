// Replace the content in <>
// Identify your target audience and explain how/why they would use this Quick Start.
//Avoid borrowing text from third-party websites (copying text from AWS service documentation is fine). Also, avoid marketing-speak, focusing instead on the technical aspect.

https://jfrog.com/artifactory/[JFrogâ€™s Artifactory^] is an enterprise, universal, repository manager that is capable of hosting
all of your binaries in one place. This Quick Start deploys Artifactory Enterprise in a highly
available (HA) configuration in the AWS Cloud.

This Quick Start is for administrators who want the flexibility, scale, and availability of AWS through products such as virtual private clouds (VPCs), Amazon Elastic Compute
Cloud (Amazon EC2), Amazon Elastic Kubernetes Service (Amazon EKS), Amazon Simple Storage Service (Amazon S3), Elastic Load Balancing (ELB), and Amazon Relational
Database Service (Amazon RDS) to deploy Artifactory as their repository manager.

Amazon EC2 and Amazon EKS, along with Amazon S3 and Amazon RDS, form the foundation for the deployment. By using Amazon S3 and Amazon RDS as persistent storage
for artifacts and the configuration, respectively, Artifactory can be completely redeployed, scaled up, or scaled down, depending on your requirements. This configuration 
allows organizations to save on costs for multiple secondary nodes and to pay only for storage used.

This Quick Start configures an https://aws.amazon.com/eks/[Amazon EKS^] cluster comprising two partitions, each with its
own https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html[Amazon EC2 Auto Scaling^] group. One partition is labeled `artifactory-primary`. The
other is `artifactory-secondary`. The number of primary https://kubernetes.io/docs/concepts/architecture/nodes/[Kubernetes nodes^] is hardcoded to
one, with the Auto Scaling group configured to boot a node into another Availability Zone
upon a failure. The secondary instances can scale up to eight https://kubernetes.io/docs/concepts/architecture/nodes/[Kubernetes nodes^] and can be
run in any of the three Availability Zones; however, there must be enough nodes available
to run the number of secondary https://kubernetes.io/docs/concepts/workloads/pods/pod/[pods^]. The deployment is configured and managed via
https://helm.sh/[Helm^]. The bastion host is preconfigured with the https://helm.sh/docs/helm/#helm[Helm^] and https://kubernetes.io/docs/reference/kubectl/kubectl/[Kubectl^], which can be used to
check or manage the cluster.

A Network Load Balancer is configured to provide ingress to the VPC and to forward traffic to the NGINX pod, which provides ingress and load balancing to the Artifactory pods within
the deployment.